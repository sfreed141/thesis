\chapter{Introduction}

Computing realistic lighting in virtual applications is an ongoing issue in computer graphics. In general, lighting at a given point is a combination of direct and indirect light. Direct light is light accumulated directly from a light source and is straightforward to compute. Indirect light is the light that comes from other non-light sources in the scene (i.e.\ the light that has `bounced' off of objects in the scene). Another term for this is global illumination, as it is the light that comes from anything in the scene. Global illumination is extremely expensive to compute in real time. The theoretical solution to the radiance of a particular point, given by Kajiya~\cite{kajiya1986rendering}, is essentially an accumulation of incoming light coming from all possible directions (i.e.\ a surface integral over a hemisphere). Performing this integral accurately is not feasible under real-time constraints and thus it must be approximated.

Many approaches on how to accurately and efficiently compute global illumination exist. Ray tracing is one popular approach, which involves sending rays out into the scene and sampling direct and indirect lighting. However, ray tracing in general is not fast enough when applied to real-time applications such as games. For real-time global illumination, a common approach is to first construct a spatial representation of a scene's radiance. This can then be used to approximate the radiance at a given point in the scene. Popular methods that follow this approach are baked lighting, light propagation volumes~\cite{kaplanyan2010cascaded}, and voxel cone tracing~\cite{crassin2011interactive}. The advantage of baked lighting is the radiance is all pre-processed once prior to runtime. The obvious disadvantage is it does not capture dynamic movement within the scene---an important part of any interactive application. Light propagation volumes are able to produce good results for dynamic scenes but suffer from issues with light bleeding. Voxel cone tracing also produces good results for dynamic scenes but has similar issues with light bleeding.

For this paper, a new technique based on voxel cone tracing will be developed. The general voxel cone tracing algorithm relies on approximating the scene's radiance using a voxelized spatial data structure, which then upscales (filters) the radiance in order to obtain adequate performance. To perform the actual lighting calculation, the radiance is sampled from the spatial data structure in such a way to minimize the amount of sampling without sacrificing quality. NVIDIA's implementation, VXGI, is a slightly modified version of the algorithm as stated in the original paper that uses clipmaps instead of octrees for the voxelized radiance values~\cite{nvidiavxgi}. VXGI has been incorporated into Unreal Engine. The idea has also been adapted and implemented in the PS4 game \textit{The Tomorrow Children}~\cite{mclaren2016cascaded}.  Unfortunately there are still issues regarding GPU memory consumption, inaccurate specular reflections, and light bleeding. In this paper, different approaches to parts of voxel cone tracing will be explored in order to find desirable tradeoffs in terms of lighting quality, performance, and memory usage. One specific area investigated will be experimenting with the data structure and filtering used in voxelizing the scene. Other promising directions are alternate radiance representations, temporal coherency, and adapting visibility techniques similar to those used in~\cite{mcguire2017real} in order to alleviate light bleeding.

The main contribution of this paper will be a novel way of computing global illumination based on voxel cone tracing. This method will focus on a new way of representing radiance in a given scene. The goal is on ease of use and speed while still producing high quality results. We hope this will provide a competitive alternative to existing real-time global illumination systems.
